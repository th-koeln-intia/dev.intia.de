# Bewertungs- und Evaluationskriterien für Prototyping-Sets

## Abstract

Das nachfolgende Dokument beschreibt die Erstellung und den Aufbau eines Konzeptes mit dem Prototyping-Sets Evaluiert und Bewertet werden. Dabei wurden zwei Hauptziele fokussiert. Zum einen eine Vergleichbarkeit von System zu ermöglichen die zum Teil Grundverschieden sind, aber alle die Gemeinsamkeit haben das sie zum erstellen von Prototypen ermöglichen. Zum anderen wurde eine Struktur geschaffen die es für Laien und Experten möglich macht die Vorzüge eines Sets schnell zu erfassen, um den eigenen Auswahlprozess zu erleichtern.
Da für diesen zweck keine brauchbaren Ansätze ausfindig gemacht werden konnte wurde durch einen explorativen Ansatz selbstständig Kategorien erstellt und ein Mustervorgehen bestimmt.
Das Herzstück dieses Vorgehens sind die, in drei Hauptkategorien unterteilten, Kriterien die versuchen ein möglichst objektive Abbildung der Eigenschaften eines Systems abzubilden. Allerdings gehört zu diesem Konzept auch ein subjektiv ausgelegtes Review, das vor allem der Zugänglichkeit und Vertiefung dient und ein Möglichkeits-Schema das losgelöst von der art der Realisierung eine Auflistung der funktionalen Bauelementen darstellt.
Das präsentierte Ergebnis ist nicht als abgeschlossenes System zu betrachten sondern muss und wird weiterentwickelt. Für weitere Iterationsschleifen, die dieses Konzept durchlaufen wird, ist ein Diskurs nicht nur Erwünscht sondern zwingend erforderlich.


## Einleitung
Obwohl nun schon seit einigen Jahren Technik-Systeme und Prototyping-Kits in und für den MINT bereich existieren, und auch wissenschaftlich Betrachtet wurden (QUELLE!), finden sich kaum bis keine brauchbaren Vergleichskriterien für eine umfangreiche Evaluation dieser. Aus diesem Grund können bestehende Arbeiten kaum herangezogen werden um diese, ohne größeren Aufwand, zu vergleichen.

Der Kontext dieses Projektes sieht eine Vergleichbarkeit allerdings vor. Somit ist es notwendig solche kriterien zu entwickeln und diese für verschiedene Zielgruppen nutzbar zu gestallten. Zum einen muss das System für andere Forscher nachfolziehbar sein und eventuell sogar Anwendbar sein - im ideal noch vor abschluss dieses Projektes um so früh es möglich ist weitere Systeme zur betrachtung heranziehbar zu machen. Des weiteren müssen auch Leihen die kriterien verstehen und nutzen können. So können, zuvor schwer vergleichbare Konzeptionen, betrachtet werden und für entsprechende anwendungszwecke ausgewählt werden.

Der Fokus liegt auf Prototypingsets da diese eine hohe relevanz für INTIA besitzen. Verscheidene Sets lasen sich schwer vergleichenda sich diese in vielen Faktoren wie Reifegrad, Anwendungsbereich, Interoperabilität und weitere unterscheiden. Diese unterschiede lasen sich nicht binär betrachten da je nach Fokus, den sich eine Entwicklung selbst setzt, spetzialeigenschaften unterschiedliche qualitätskriterien abdecken. Eine tiefeliegende Frage ist ob eigenschaten in wechselwirkung zueiander stehen. Ein beispiel ist Programmierbarkeit zu Usibility: kann eine vereinfachte und eventuell "Kinderfreundliche" Programmierumgebung hohe Flexibilität und Programmiertiefe aufweisen? Die beantwortung solcher Fragen benötigen zur annäherung und auswertung ein Fundament das hier Gestalltet wird. Diese Erkenntniese werden intensiven einfluss auf die Zusammenstellung der Koffer nehmen. 

Die Kriterien sind, so fern möglich,  transponierbar gestaltet. Sie bilden die Basis für die Betrachtung der Visuellen Programmierumgebungen (QUELLE IN ZUKUNFT). 

Wie bereits erwähnt sind Zielgruppe des Bewertungssystems Experten wie Leihen. Experten müssen hier geteilt als Wissenschaftler und Techniker betrachtet werden. Der Wert für die Wissenschaft ist bereits besprochen worden. Technicker, also Personen mit Wissen über Technologien und Fahrtätigkeiten wie Programmieren sollen adressiert werden. Hierbei ist der Grad der Expertise nicht definiert. Es wird impliziert das Personen, die beispielsweise nur Grundlegende Programmierkenntniese beseitzen, in der Lage sind die theoretischen Möglichkeiten zu interprätieren.
Leihen sind Nicht-Techniker, die eventuell aber nicht zwangegebunden soziale kompetänzen aufweisen. Diese sollen ermöglicht werden, ohne hilfe von Experten, den möglichkeits-umfang der verglichenen Systeme zu erkennen und für den persönlichen bedarf im auswahlprozess unterstützt werden. Solche Bedarfsunterscheide finden sich zum einen in der Zielgruppe und eventueller einschränkuen wie auch in dem gewünschten ziel. Das Ziel kann das erlernen gewisser fähigkeiten sein oder gestallten einfacher prototypen (ohne Vorerfahrungen).

Da das Ziel großen Einfluss auf die Betrachtung der Kriterien nimmt müssen die Überkriterien seperat betrachtet werden.

Das hier vergestellte Bewerzungs- und Evaluationskonzept erhebt nicht den anspruch fertig oder perfekt zu sein. Es muss weiter Evaluiert und weiterentwikelt werden. Aus diesem Grund ist eine Versionierung wichtig.

## Vorgehen
Innerhalb der Wissenschaft finden sich kaum dokumentierte Bewertungskonzepte, für den hier beschrieben Anwendungsrahmen, die den anspruch der Vergleichbarkeit erhaben. Zwar wurd inspiration aus anderen quellen genommen, im spitzielen der Technikbewertung im bereich der Betrieb- und Firmenanschafung (QUELLE!). Die dort vorgefunden kriterien konnten allerdings kaum übernommen werden.

Es wurde ein exploratiever ansatz ausgewählt. Ein als Prototyping-Set einsetzbares System aus dem Education-Kontext wurde ausgewählt (QUELLE!) und ohne Vorgehensmodell von erkundet. Der Tester (wie schreibe ich schön das ICH das bin? mache ich das?) kommt aus dem IT-Bereich und weißt fortgeschrittene erfahrungen in dem konstruieren von digitalen Prototypen auf. Nach abschluss der mehrtägigen explorationsphase wurden die erkenntnisse in Form eine Reviews dokumentiert. Das entstandene Dokument ist stark vom üblichen Artikel-Stil einschlägiger Fachmagazine geprägt. In einem Folgeschritt wurde das Dokument von einer Person aus dem bereich der Sozialen Arbeit Verständlichkeit und Erkenntnisgehalt geprüft. Wärend dieses Prozesses wurden bereits Begriffe gesammelt die wichtige Aspekte repräsentieren können. Dieser Prozess belegte eine zuvor aufgestellte Vermutung - die Erstellung einer geeigneten Bewertung benötigt interdisziplinäre Kompetänzen da unterschiedliche Wissenbasen und Betrachtungsfokus eine Lückenarme bewertung entgegenwirken.

Nach Abschluss des Review-Dokumentes wurde anhand dieses, mit einer Gruppe aus unterschiedlichen fachdisziplinen, weitere begrieffe extrahiert und mit den zuvor ermittelten weiter betrachtet. Die Begriffe wurden logisch verwunden und zusammen geführt und lücken ermittelt. Zum abschluss wurden drei Haupt-Kategorien definiert, unter denen die Kriterien unterteilt wurden: User-friendliness, Prototypingfähigkeit und Ecosystem.

Bereits während der Explorations-Phase wurde ein standartisiertes Vorgehen für die Evaluation und Exploration weiterer Systeme geplant. Im nachfolgendem abschnitt wird dies beschrieben.

## Evaluations- und Explorationsphase
Bevor eine Bewertung und Evaluation des Systems durhgeführt werdenn kan muss der Reviewer sich mit dem Produkt vertraut machen.
Zu beginn wird dies oberflächlich gemacht. Welche Angaben macht der Hersteller zum Produkt? Für wenn hat der Hersteller das Produkt als Hauptzielgruppe entwickelt? Wie ist der Formfaktor des Produktes, wie die Verpackung (z.B. wird ein Koffer für einen besseren Transport mitgeliefert) und welche Variationen werden angeboten? Und zu letzt die Preispolitik des Systems. Gemeint sind nicht nur die Anschaffungskosten sondern auch eventuelle Folgekosten zur Software, Abos oder das Erweitern nach Nachkaufen von Systemelemente.

Nach abschluss der betrachtung des Rahmens kann die Explorations-Phase beginnen. Besonders wichtig für die spätere Bewertung ist das die Zeiten zu Dokuemntieren. Das Auspacken sowie die Erstinbetreibnahme können Zeitintensiv sein. Diese Faktoren spiegeln sich nicht nur in der Bewertung direkt wieder sondern können für Interessierte des Systems wichtige Informationen darstellen. Soll ein System für eine Einrichtung angeschaft werden so kann es ein großen Faktor spielen ob etwas in 5 Minuten Ausgepackt und Vorbereitet ist oder ob jedes Paket, eventuell weil noch Kabel und andere Elemente vorbereitet werden müssen, noch zuvor von einer Person eingerchtet werden muss. Nach dieser Vorbereitung kann bereits das Möglichkeits-Schema ausgefüllt werden. Dieses soll immer wieder heran gezogen werden wodurch es nicht dramatisch ist wenn hier Lücken gelasen werden oder fehler gemacht werden.

Ist die erste Exploration abgeschlossen gilt es die mitgelieferte Anleitung zu Studieren, weitere Dokumenationen zu suchen und eventuell auch Communitys und andere Fakoren zu prüfen. Zum studieren der Anleitung kann es gehören Modelle aus dieser nachzubauen. Mit diesem Schritt kann sich nicht nur mit dem System vertrauter gemacht werden sondern mögliche problematiken mit einer Anleitung aufgezeigt werden. Ein Beispiel findet sich bei der Betrachtung der Fischertechnik-Anleitungen. Bei der oberflächlichen betrachtung ist jeder Schritt gut bebildert und diese Wirken nachvollziebar. Erst beim bevolgen der gezeigten Anweisungen wird festgestellt das Teils, durch Unterschneidung in der Bildperspektive, ein exaktes bevolgen schwer fällt und das die Auswahl der korrekten Teile nicht immer anhand der gegeben Bilder geliengt. An dieser stelle können bereits ein Teil der Bewertungskriterien im Bereich Ecosystem und einige im bereich User-friendliness ausgefüllt werden. Nach abschluss der gesammtbewertung ist eine abschließende Iteration vorgesehen weshalb fehler an dieser stelle später kompensiert werden können.

Es folgt ein Benchmarking des betrachteten Systems. Zu diesem Zweck werden einige vordefinierte Projekte gebaut. Diese Projekte werden frei bewertet nach Form, Qualität und Funktion also in wie weit das Ziel erfüllt werden konnte. Die benötigte Zeit zu messen kann hier vorteile haben, allerdings muss klar sein das diese nicht als objektiver Messwert betrachtet werden kann da zusatzfaktoren die sich vom Test ableiten eine vergleichbarkeit zu anderen Systemen verfälscht.

Die Benchmark-Projekte unterscheiden sich in Komplexität und Ziel, beantworten aber als Ergänzung am ende immer die selbe Frage: kann das Projekt in "unser" System intigriert werden? Diese Frage wirkt auf dem ersten Blick vorallem für projektferne Anwender dieses bewertungsschemas uninteresant. Bei genauerer betrachtung ist dies dennoch einfach zu beachten. Liegt ein weg vor, und wurde dieser auch getestet, um ein System mittels Wifi mit einem MQTT-Server zu verbinden ist diese Frage bereits bejaht. Ansonsten finden sich 3 Hauptthemen und ein ergänzendes Bonus-Projekt: Rufsystem (taktil), Lautstärkemesser (akustisch), Lichtsteuerung (optisch) und ergänzend eine Sensorstation. Die Sensorstation gilt als ergänzend da es versucht alle Elemente eines Systems zusammen zu führen. Die Sensorstation ist vorallem als Kontroll-Projekt für das Möglichkeits-Schema von nutzen, kann aber im zweifel vernachlässigt oder rein theoretisch durchgeführt werden.

Die Projekte unterteilen sich zusätzlich in Unterziele. Es Folgt eine Auflistung:

### Rufsystem:
a. Knopf wird gedrückt und an einer anderen stelle erscheint ein Text

b. An einem Rad wird ein name Ausgewählt

c. Kann das Display feedback in Form von Vibration oder Ton geben?

d. Vernetzung mit unserem System
### Lautstärkemesser
a. Ein Mikrofone zeichnet umgebungsgeräusche auf. Eine Anzeige gibt Feedback.

b. Vernetzung mit unserem System
### Lichtsteuerung
a. Eine ansammlung von Knöpfen und Hebeln die einfluss auf ein Licht haben

b. Vernetzung mit unserem System
### Sensorstation
a. Vernetzung mit unserem System

In Folge sollte das System und der damit verbundene Aufwand geschätzt werden. Dies aus vier verschiedenen Perspektiven:

- für sich selbst

- für Experte

- für Enthusiast

- für Anfänger

Die Schätzung kann heran gezogen werden wenn es um die Iteration der Bewertungskriterien geht. Zum Abschluss der Evaluations- und Explorationsphase werden, bevor die Bewertungskriterien final betrachtet und überarbeitet werden, noch folgende Fragen kurz Beantwortet:

- Macht das System Spaß? Was schmälert den Spaß?

- Ist das System, im vergleich zu bekannten Konkurrenten, sinnvoll und konkurrenzfähig?

- Lässt sich das System kombinieren (zum Beispiel mit Lego oder anderen Systemen)?

- Für wenn ist das System geeignet?

- Wie schwer wäre es verschiedene Zielgruppen zu motivieren das System zu nutzen? Was steht dem im Weg?

- Kann das System alleine genutzt werden? Aus welchem Grund ist das nicht möglich?

Die Beantwortung der Fragen unterstützt nicht nur die Bewertung sondern hilft beim schreiben des (subjektiven) Reviews. Wichtig in hinblick auf das Review ist das dokumentieren des Prozesses. Fotos sind unersätzlich fürs Verständnis und verbessere die Zugänglichkeit.

Nach Abschluss sollten auch die Bewertungskriterien vollständig ausgefüllt sein. Bei der abschließenden Iteration sollte die Gewichtung der Bewertung hinzugezogen werden. Diese schlüsselt die Bewertung detaillierter auf und gilt ebenfalls zur Kontrolle. Im Nachfolgenden Abschnitt wird detailliert über die Bewertungskriterien gesprochen.

## Bewertungskriterien
Aktuell setzt sich der Kriterienkaterlog aus 20 Kriterien zusammen welche in 3 Überkategorien unterteilt werden. Diese sind User-friendliness, Prototypingfähigkeit und Ecosystem.
Jedes Kriterium wird in einer Skaller von 1 - 10 bewertet und besitzt eine indiwieduelle Gewichtung. Die Gewichtung beeinflusst in wie weit ein Kriterium einfluss auf die Gesammtbewertung der Kategrien nimmt. Zum Abschluss werden die Kategorien ebenfalls gewichtet zusammen geführt. Bei der Bewertung der Kriterien wurden eigenschaften im Allgemein schwächer bewertet wenn diese Experten-Wissen voraussetzen. Kriterien die auch Leihen, also im ideal ohne Vorwissen, zu kommen werden unabhängig anderer Faktoren höher bewertet. Finden sich Zeitangaben in der Bewertung so muss zwischen der Zeit selbst und Tagen als Aufwand differenziert werden. Faktoren wie "Einarbeitungszeit" können eine komlexität aufweisen bei den eine Vertagung von Nutzern schon nach kurzer Zeit gewünscht ist (Gründe dafür kann Komplexität aber auch fehlender "Fun_Factor" sein). So kann eine Einarbeitung effektiv wenige Stunden in anspruch nehmen aber sich über mehrere Tage ziehen. In diesem Fall muss die Bewertung schwächer ausfallen.

Es folgt eine nähere Betrachtung der Kriterien:

### User-friendliness
In dieser Kategorie werden Kriterien betrachtet die Einfluss auf die Nutzbarkeit und das Nutzungserlebnis eines Systems nehmen. Es ist anzunehmen das diese Kategorie für Nicht-Experten, also Leihen, den höhsten Stellenwert besitzen. Hürden die vor und während der Nutzung auftreten können wirken sich hier am stärksten aus. Folgende Kriterien sind Teil dieser Kategorie:

Erstinbetriebnahme - benötigt ein System explizit mehr Aufwand bei der Ersteinrichtung. Es sind Punkte die bei der wiederholten Nutzung nicht auftreten sollten.

Vorbereitungszeit - in Abgrenzung zur Erstinbetriebnahme bildet dieser Punkt Aspekte ab die bei jeder Nutzung beachtet werden müssen. 

Vorkenntnisse - solche Kentnisse kann Wissen über das System sein oder Expertenwissen wie aus den bereichen der Elektrotechnik, Mechanik, Informatik und ähnlichen sein.

Anleitung - Ob durch schriftliche Anleitungen oder eine Person als Unterstützung kann die Nutzung eines Systems unterstützt werden. Ein ideales System kommt ohne jegleiche Anleitung aus und ist Selbstbeschreibend.

Einarbeitungszeit - muss ein System erlernt werden? Werden Personen signifikant erfolgreicher mit einem System durch häufige nutzung oder wird sogar eine Einarbeitung vorausgesetzt (für eine Zielorientierte Nutzung).

Programmier-Komplexität - Dieses Kriterum muss in abgrenzung zur Programmierbarkeit betrachtet werden. Ob etwas Programmiert werden kann sagt nicht darüber aus ob es einfach ist dies zu tun. Grafische-Benutzeroberflächen und das bereit stellen von Werkzeugen kann sich positiv auf die Komplexität auswirken und es Leihen einfach machen, ohne Vorkenntnisse, erfolge mit dem System zu erfahren.

Robustheit - dieses Kriterium kann Aufschluss über analoge und digitale Stabilität eines Systems geben. Digitale Robustheit sagt aus das ein System gut auf Benutzungsfehler reagiert und nicht zu abstürzen neigt. Analoge Robustheit gibt rückschluss über die Stabilität eines Prototypen und den Bausteinen eines Systems. Mutmaßliche Zerstörungbarkeit wird nicht abgebildet. Es ist anzunehmen das Personen die ein Produkt unsachgemäss Nutzen und dieses Beschädigen wollen auch erfolg haben werden.
### Prototypingfähigkeit
Die Kriterien dieser Kategorie versuchen die Machbarkeiten abzubilden. Zusammen betrachtet zeigen diese auf welche möglichkeiten ein Prototyp abbilden kann und wie die qualität dieses sein kann. Damit bewegt es sich nicht nur um Aspekte wie Programmierung und Mechanik sondern auch um Qualitäten wie Optik oder Haptik. Es ist anzunehmen das für Entwickler diese Kriterien den höhsten wert bitten. Folgende Kriterien sind Teil dieser Kategorie:

Funktionalität (Mechanisch) - ist es möglich mit einem System verschiedene physische Ziele zu erreichen. Ein beweglicher Arm ist hier ein Beispiel für ein Mechanischer Prototyp.

Funktionalität (Digital) - kann das System, über Programmierung, viele Ziele abbilden. Zur Vereinfachung der Usibility werden digitale Funktionalitäten oft ausgeschlossen. Die wechselwirkung zwischen digitaler Funktionalität und Usability steht in verdacht in einer Wechselwirkung zu stehen.

Programmierbarkeit - Nicht nur der Umfang der programmierbaren Funktionalität spielt für dieses Kriterium eine Rolle. Die Auswahl verschiedener Programmiersprachen und Paradigmen kann ebenfalls ein wichtiges Kriterium für die Auswahl eines Systems bieten. Ein Beispiel sind Systeme die eine grafische Programmiersprache bieten, zeitgleich aber einen den umgang mit einer klassischen Programmiersprache anbieten (Bsp.: Blocks und JavaScript).

Konstruktion - was kann mit dem System Abgebildet werden? Form und Farbe sind betrachtungspunkte für dieses Kriterium. Systeme wie Lego, bei dem Steine in vielen Farben vorliegen, und Fischertechnik, bei dem Steine mit kleinen Winkelunterschieden komplexere Konstruktionen ermöglichen, sind hier populäre beispiele.

Geschwindigkeit - Wie schnell können komplexere Prototypen konstruiert werden? Dieses Kriterium steht in verdacht in Wechselwirkung zur Funktionalität und Konstruktion zu stehen.

Ease of Make - Ist es einfach einen Prototypen zu konstruieren (ohne Vorkenntnisse). Beispiel ist Lego das einfacher zu sein scheint als Fischertechnik.

Quality of Make - welche Qualität hat ein Prototyp, der mit dem betrachteten System konstruiert wurde? Handelt es sich um einen reinen Funktionsprototyp (bzw. Prof of Conzept) oder ist es möglich richtige Alltagsprodukte zu erstellen?
### Ecosystem
Bei dieser Überkategorie handelt es sich um die veilleicht am schwesten zu greifende. Sie betrifft weniger das System selbst und mehr Rahmenfaktoren. So geben Kategorien wie Community oder Support mehr wieder in wie weit ein Produkt aktiv von anderen Personen verwendet und weiterentwickelt wird. Durch solche Faktoren kann abgebildet werden in wie weit unterstützung von Dritten einzuholen ist. Der Fokus liegt nicht alleine auf diesen Eigenschaften sondern auch um ergänzende Infos wie Zielgruppen oder der Grad an Sicherheit. Anders als die zuvor genannten Hauptkriterien kann dieser Bereich schwer einer Personen Gruppe zugeordnett werden. Mehr ist dies als Meta-Kriterien zu verstehen die für die meisten Ergänzende Entscheidungskriterien liefern. Folgende Kriterien sind Teil dieser Kategorie:

Zielgruppenbreite - wenn ein System mit einer klaren Zielgruppe im Blick entwickelt wird bedeutet das zwar nicht automatisch das andere Zielgruppen ausgeschlossen werden, dennoch können Faktoren entstehen die andere Gruppen abschrecken. Ist ein Produkt für Vorschüler entwickelt worden kann die Erscheinung die aktzeptanz bei erwachsenen Menschen negativ beeinflussen.

Community - eine große und kreative Nutzerschaft fördert nicht nur den Erfolg sondern Gerantiert oft auch unterstützung. Ein beispiel ist der Erfolg des Raspberry Pis, der zwar viel konkurenz besitzt aber dennoch besteht auf Grund der größten Community. Bei der Planung eines Projektes ist es nicht unwahrscheinlichd as etwas ähnlcihes bereits mit diesem Kleinstcomputer bereits umgesetzt wurde und hilfe bereit steht. Bei der Bewertung wird eine aktive Community positiver bewertet als ein umfangreiches Archiv.

Reifegrad - ist ein System noch in einer frühen Alpha oder bereits seit vielen Jahren ein erfolgreichs Produkt.

Support - Dieses Kriterium bildet zwei hauptaspekte ab. Zum einem wie gut und von wem unterstützung für ein System kommt. Dabei ist Unterstützung die auch für Leihen zugänglich ist besser zu bewerten als Expertenunterstützung die mehr tiefe besitzt (auf Grund des gesammtziels dieser Bewertung). Zum anderen in wie weit das System noch Weiterentwickelt wird. Ist die Entwicklung abgeschlossen oder gibt es weiterhin Updates vom Hersteller?

Sicherheit - unter diesem Punkt wird betrachtet in wie weit eine Gefahrlose Nutzung gewährleistet werden kann. Dabei wird erst ab einer Wertung von 6 Punkten die IT-Sicherheit betrachtet. Zum einen ist bei einem System bei dem die Gesundheit in Gefahr ist die IT-Sicherheit zweitrangig. Zum anderen ist es sehr schwer die IT-Sicherheit zu bewerten. Ohne großen Aufand und Expertiese ist eine detailierte Prüfung nicht möglich. An dieser stelle wird nur eine kurze recherche erwartet. Ist ein Produkt bekannt dafür Angreifbar zu sein muss dies vermerkt werden. Vorsichtig sollte man mit einfahen News sein. Viele Lücken die in den Medien besprochen werden sind oft bereits Geschlossen. Wenn ein Entwickler (siehe Aplle oder Google) zügig Lücken schließt muss dies positiv bewertet werden. Bei Populären Produkten ist die wachscheinlichkeit hoch das Lücken gefunden werden weil diese auch für angreifer aktraktiver sind. Das macht diese nicht weniger sicher sondern teilweise sogar sicherer.

Kompatibilität - Systeme können auf verschiedenen wegen Kompatibel mit anderen sein. Eine einfache Form der komptaibilität findet sich bei veieln systemen die erweiterungen haben um das LEGO-System nutzen zu können (Siehe Dash Robotor oder Sam Steam Kit). Ebenfalls populär ist die kompatibilität zu IFTTT (QUELLE!). Unterstützt ein System protokole wie MQTT oder Webhooks kann dieses als sehr offen betrachtet werden. Auch wichtig ist zu betrachten wie groß der Umfang der offenen Funktionen ist.

Eine Vorlage für die Bewertungskriterien befindet sich auf GitHub (QUELLE!) für Microsoft Excel. Teil der Vorlage ist auch eine Gewichtung welche deutlicher aufschlüsselt was die Nummerische-Bewertung über den entsprechenden Punkt aussagt.

Die Bewertungskriterien versuchen, wie bereits besprochen, das betrachtete System möglichst objektiv und vergleichbar zu repräsentieren. Allerdings kann dies für den Auswahlprozess zu abstrakt sein. Um dem entgegen zu wirken wir zusätzlich, als Repräsentation der subjektiv zu betrachtenden Aspekte, ein Review erstellt. Dieses wird nun Betrachtet.

## Review
Die Bewertungskriterien bieten eine klare und vergleichbare Einschätzung über das betrachtete System. Durch den versuch eine solche, möglichst objektive, Vergleichbarkeit aufzustellen können Erkenntnisse und Aspekte die eher subjektiv zu werten sind kaum abgebildet werden. Aus diesem Grund kann es von Vorteil sein ein, von den Bewertungskriterien losgelöst, Review zu Formulieren. Die Freiheiten eines Reviews bieten Raum um Erlebnisse, Erkenntnisse, Vergleiche zu anderen System und explizite Beispiele unter zu bringen.

Bei der Erstellung eines Reviews sollte dennoch darauf geachtet werden so weit es geht eine subjektive Position ein zu nehmen. Persönliche Meinungen aus vergangenen Erfahrungen oder unbegründeten Positionen (bsp.: ich mag LEGO mehr als Fischertechnik weil ich damit aufgewachsen bin) haben in einem Review nichts zu suchen. Annahmen die nur schwach untermauert werden können hier geäußert werden (bsp.: da die meisten vermutlich schon mit LEGO gespielt haben wird dieses System vermutlich schneller akzeptiert). Dennoch gilt das wenn etwas zu belegen ist oder sich auf eine externe quelle berufen wird dies kenntlich gemacht und korrekt zitiert werden muss. Zielgruppe des Reviews sind interessierte Leihen und Experten die bereits eine Vorauswahl getroffen haben und nun konkrettere, subjektive, meinungen über ein System einholen möchten. Somit gilt auch das der Text Frei gestalltet ist und Struktur und Inhalt nicht standartisiert wird. Dennoch sollte er den anspruch eines redaktionäl geprüften Review-Artikels erhoben werden. Ein Review muss von Experten unterschiedlicher Disziplinen geprüft werden da nur so sicher gestellt werden kann das dieser auch für Nicht-experten zugänglich ist.

Am ende des Review-Artikels steht eine Pro- und Kontraliste. Diese Aufstellung ist bei vielen Reviews standard ist liefert in stichpunkten eine übersichtliche zusammenfassung. Trotz der struktur ist auch diese Aufstellung eindeutig subjektiv geprägt, ist aber leichter zu vergleichen als der Review-Artikel.

Möglichkeits-Schema
Beim Möglichkeits-Schema handelt es sich um eine Darstellung die den Inhalt bzw. die Bausteine abbildet. Es lässt sich schnell erfassen ob ein Kit Elemente wie Buttons, LEDs und andere Aktoren und Sensoren beinhaltet. Es wird in drei Kategorien geteilt: aktive Steuerung, passive Sensorsteuerung und steuerbare Elemente. Die Bezeichnungen wurden so gewählt um besonders niederschwellig auch für Leihen Funktionen und Möglichkeiten darzustellen.

Aktive Steuerelemente sind Interaktionsmöglichkeiten beidenen der nutzer aktiv mit einem System Interagiert wie durch einen Dreh-/Schieberegler oder mit Sprache. Passive Sensorensteuerung bilden Sensoren und Technologien ab die genutzt werden können um durch Veränderungen weitere Programmabläufe anzustoßen. Ein Beispiel für solch einen Programmablauf währ ein Bewegungssensor oder der Einsatz einer Kamera die eine Präsenz in einem Raum ermitteln und so ein steuerbares Element wie Licht verändern. Die Unterteilung spiegelt hier nicht eins zu eins Sensor oder Funktion ab sondern sind so gewählt das es für den Ersteller der Bewertung und für den Leser möglichst einfach gemacht wird auf ein Element des betrachteten Systems zu zeigen. Steuerbares Elemente sind End-Punkte an die entsprechende Befehle und Programme Adressiert werden können wie Licht oder Sound. Bewegung repräsentiert stellvertretend alles was eine Bewegung erzeugen oder durchführen kann. Somit ist dies ein Sammel-Punkt für Motoren aber auch für dinge die Fahren und sogar Greifen können.

Dieses Schema bildet nicht nur den Möglichkeits-Horizont eines Systems oder Kits ab. Es dient auch als Möglichkeits-Benchmark für den Koffer. Wenn ein System nicht alle Punkte des Schemas abdeckt kann dahinter eine bewusste Endscheidung der Entwickler Stecken um durch Einschränkung des eigenes Systems die Zugänglichkeit für Nutzer zu verbessern. Der Koffer selbst hat aber den Anspruch möglichst kompromieslos alle Elemente abdecken zu können. Somit hilft dieses Schema aus den Ergebnissen andere Systeme zu lernen wie es möglich sein kann alles hier beschriebene zu erfüllen.

## Ausblick
Abgesehen von einer weiterentwicklung dieses Bewertungs-Konzeptes bietet dieser Kriterien-Katerlog und das Vorgehen großes potenzial für die Transponierung in andere Bereiche. Ein beispiel hierfür zeigt sich in den Bewertungskriterien für Grafische-Programmierumgebungen, die auf diesen basieren. Das hier vorgestellte Konzept darf gerne als Einladung gesehen werden es für weitere Bereiche zu adaptieren. Es ist anzunehmen das weitere Adaptionen, und die zugehörigen anpassungen, sich auf diese Kriterien rückspiegeln und helfen sie weiterhin zu optimieren.

## Fazit
Das hier besprochene Konzept zur Bewertung von Prototyping-Sets darf, wie zu beginn beschreiben, nicht als perfekt und fertig betrachtet werden. Dennoch erfühlt dieser bereits die zuvor definierten Ansprüche. Mit hilfe dieser Evaluations- und Bewertungskriterien können Prototyping-Sets erprobt, Bewertet und Vergleichen werden. Ebenfalls scheint der Anspruch der zugänglichkeit für andere Erfolgreich erfüllt zu sein. Kritik und Feedback sind an dieser stelle explizit erwünscht, den schließlich handelt es sich hier um ein Konzept das auch in den kommenden Jahren Aufmerksamkeit und Iterationsschleifen bedarf. Dies kann aber nur ermöglicht werden durch einen Umfangreichen Katerlog an Systemen die mit diesem Konzept bewertet wurden.
